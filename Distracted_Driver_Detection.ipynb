{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import math,time\n",
    "#import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "#torch.multiprocessing.set_start_method(\"forkserver\")\n",
    "\n",
    "import torch as tc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import models\n",
    "from torch.utils.data import  Dataset, TensorDataset\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sys.path.append('/mnt/home/e209440/')\n",
    "#sys.path.append('/home/r120084/pytorch_lib/pytorch')\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "from src.imgnet_utils import my_transforms,denormalize\n",
    "\n",
    "from src.data_loader import _create_dataLoader\n",
    "\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "#cpu_count = 24 #torch.multiprocessing.cpu_count()\n",
    "\n",
    "print('GPU available:', use_gpu)\n",
    "#print('cpu_count: ', cpu_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Choose dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nelse:\\n    path2train = \"/home/r120084/project/data/train\" #server without gpu\\n    path2test = \"/home/r120084/project/data/test\"\\n    \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if use_gpu:\n",
    "path2train = \"/mnt/home/e209440/data/train\" # with gpu \n",
    "path2test = \"/mnt/home/e209440/data/test\" \n",
    "'''\n",
    "else:\n",
    "    path2train = \"/home/r120084/project/data/train\" #server without gpu\n",
    "    path2test = \"/home/r120084/project/data/test\"\n",
    "    \n",
    "'''    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#        transforms.RandomHorizontalFlip(), First try withouth Data Augmentation \n",
    "        transforms.Lambda(my_transforms),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Lambda(my_transforms),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating  Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 320\n",
    "\n",
    "use_only = 0.5 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'train': KaggleSafeDriverDataset(path2train, transforms=data_transforms['train'],use_only=use_only),\n",
    "    'valid': KaggleSafeDriverDataset(path2train, transforms=data_transforms['valid'],use_only=use_only, is_val=True, val_size=0.2),\n",
    "    'test':  KaggleSafeDriverDataset(path2test, transforms=data_transforms['valid'],use_only=use_only, is_test=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = _create_dataLoader(dsets, batch_size, 10, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, {'test': 39863, 'train': 8970, 'valid': 2242})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['train','valid', 'test']} \n",
    "dset_classes = len(dsets['train'].y)\n",
    "dset_classes, dset_sizes\n",
    "\n",
    "# Datates has much more samples than datatrain ***It comes from the test.zip****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) 2.640000104904175 -2.1179039478302 torch.Size([320])\n"
     ]
    }
   ],
   "source": [
    "inputs,cls = next(iter(dset_loaders['train']))\n",
    "print(inputs[10].shape, inputs[10].max(), inputs[10].min(), cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(dset_loaders, labels, path2save = './figures/data.png'):\n",
    "\n",
    "    # Get a batch of training data\n",
    "    inputs, cls = next(iter(dset_loaders))\n",
    "    print(inputs[8].shape, cls.shape)\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    for i, j in enumerate(range(0,10)):\n",
    "        fig.add_subplot(2,5, i+1)\n",
    "        img = denormalize(inputs.numpy()[j])\n",
    "        img = np.clip(img, 0, 1.0)\n",
    "        plt.imshow(img)\n",
    "        plt.title('{}'.format(labels['c'+str(cls[j])]))\n",
    "        plt.axis('off')\n",
    "    fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(dset_loaders['train'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(img):\n",
    "    \n",
    "    if img.shape[2] != 3:\n",
    "        img = img.transpose((1, 2, 0))\n",
    "        \n",
    "    color_lst = ['red', 'green', 'blue']\n",
    "    for i in range(0, img.shape[2]):\n",
    "        c1=img[:,:,i].reshape(-1)\n",
    "        plt.hist(c1, 50, facecolor=color_lst[i], label = color_lst[i])\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis_image(dset_loaders, labels, path2save = './figures/distribution.png'):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    inputs, cls = next(iter(dset_loaders))\n",
    "    rand_idx = random.randrange(0, len(inputs))\n",
    "    img = inputs.numpy()[rand_idx]\n",
    "    img_denorm = denormalize(img)\n",
    "    plt.subplot(2,2,2)\n",
    "    plot_distribution(img_denorm)\n",
    "    plt.title('Image RGB after denormalization')\n",
    "    plt.subplot(2,2,4)\n",
    "    plot_distribution(img)\n",
    "    plt.title('Image RGB normalization')\n",
    "    plt.subplot(1,2,1)\n",
    "    img_denorm = np.clip(img_denorm, 0, 1.0)\n",
    "    plt.imshow(img_denorm)\n",
    "    plt.title('{}'.format(labels['c'+str(cls[rand_idx])]))\n",
    "    plt.axis('off')\n",
    "    fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_analysis_image(dset_loaders['train'], labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def code2label(dataset, labels): \n",
    "    class_str = []\n",
    "    for item in dataset.y:\n",
    "        class_str.append(labels['c'+str(item)])  \n",
    "    return class_str           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_str = code2label(dsets['train'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "sns.countplot(y=class_str, palette=\"Greens_d\");\n",
    "plt.xlabel(\"Classes\", fontsize=12)\n",
    "plt.ylabel('Counts', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Classes Distribution\", fontsize=15)\n",
    "plt.show()\n",
    "path2save = './figures/distribution_classes.png'\n",
    "fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_out = len(set(class_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myInception(torchvision.models.Inception3):\n",
    "    def __init__(self, fixed_extractor = True):\n",
    "        super().__init__(torchvision.models.inception_v3(pretrained=True))\n",
    "        self.load_state_dict(torch.utils.model_zoo.load_url(\n",
    "            'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth)'))\n",
    "        \n",
    "        if fixed_extractor:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dens1 = torch.nn.Linear(in_features=64, out_features=32)\n",
    "        self.dens2 = torch.nn.Linear(in_features=32, out_features=nb_out)\n",
    "    def forward(self, x):\n",
    "        x = self.dens1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dens2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mrnc = Inception()\n",
    "        self.mrnd = Classifier()\n",
    "    def forward(self, x):\n",
    "        x = self.mrnc(x)\n",
    "        x = self.mrnd(x)\n",
    "        return x \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNetConv(torchvision.models.ResNet):\n",
    "    def __init__(self, fixed_extractor = True):\n",
    "        super().__init__(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2])\n",
    "        self.load_state_dict(torch.utils.model_zoo.load_url(\n",
    "            'https://download.pytorch.org/models/resnet18-5c106cde.pth'))\n",
    "        \n",
    "        del self.fc\n",
    "        \n",
    "        if fixed_extractor:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class MyResNetDens(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dens1 = torch.nn.Linear(in_features=4096, out_features=512)\n",
    "        self.dens2 = torch.nn.Linear(in_features=512, out_features=128)\n",
    "        self.dens3 = torch.nn.Linear(in_features=128, out_features=nb_out)\n",
    "    def forward(self, x):\n",
    "        x = self.dens1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dens2(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dens3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MyResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mrnc = MyResNetConv()\n",
    "        self.mrnd = MyResNetDens()\n",
    "    def forward(self, x):\n",
    "        x = self.mrnc(x)\n",
    "        x = self.mrnd(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando disponibilidade de recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_resnet = True\n",
    "\n",
    "if use_resnet:\n",
    "    model = MyResNet()\n",
    "else:\n",
    "    model = myInception()\n",
    "\n",
    "if use_gpu:\n",
    "    !free -h\n",
    "    !nvidia-smi\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dset_loaders, model):\n",
    "\n",
    "    predictions = []\n",
    "    labels_lst = []\n",
    "    ii_n = len(dset_loaders)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dset_loaders):\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        inputs = Variable(inputs)\n",
    "        predictions.append(model(inputs).data)\n",
    "        labels_lst.append(labels)\n",
    "\n",
    "        print('\\rpredict: {}/{}'.format(i, ii_n - 1), end='')\n",
    "    print(' ok')\n",
    "    if len(predictions) > 0:\n",
    "        return {'pred': torch.cat(predictions, 0), 'true':torch.cat(labels_lst, 0) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    convOutput_train = predict(dset_loaders['train'], model.module.mrnc)\n",
    "    convOutput_valid = predict(dset_loaders['valid'], model.module.mrnc)\n",
    "else:\n",
    "    convOutput_train = predict(dset_loaders['train'], model.mrnc)\n",
    "    convOutput_valid = predict(dset_loaders['valid'], model.mrnc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convOutput_train['true'].size(), convOutput_train['pred'].size())\n",
    "print(convOutput_valid['true'].size(), convOutput_valid['pred'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convOutput_train['true'].type(), convOutput_train['pred'].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dset ={\n",
    "    'train': TensorDataset(convOutput_train['pred'], convOutput_train['true']),\n",
    "    'valid': TensorDataset(convOutput_valid['pred'], convOutput_valid['true'])\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders_convnet = {\n",
    "    'train': torch.utils.data.DataLoader(conv_dset['train'], 320,  shuffle=False),\n",
    "    'valid': torch.utils.data.DataLoader(conv_dset['valid'], 320, shuffle=False)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset_loaders_convnet = _create_dataLoader(conv_dset, batch_size, cpu_count, pin_memory=use_gpu, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dset_loaders_convnet['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path2saveModel = '/home/r120084/project/models/distractdriver'\n",
    "path2saveModel = '/mnt/home/e209440/models/ResNetDistractDriver' \n",
    "\n",
    "if use_gpu:    \n",
    " #   path2saveModel = '/mnt/home/r120084/project/models/distractdriver' \n",
    "    path2saveModel = '/mnt/home/e209440/models/ResNetDistractDriver' \n",
    "    \n",
    "savebest = ptt.ModelCheckpoint(path2saveModel,reset=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_epochs = 50\n",
    "\n",
    "if use_gpu:\n",
    "    optimizer =  optim.Adam(model.module.mrnd.parameters(), lr=1e-3)\n",
    "    \n",
    "    params = {'model' : model.module.mrnd, \n",
    "        'criterion': loss_fn,  \n",
    "        'optimizer': optimizer, \n",
    "        'callbacks': [savebest,  ptt.PrintCallback()] #ptt.PlotCallback(),\n",
    "    }\n",
    "\n",
    "else:    \n",
    "    optimizer =  optim.Adam(model.mrnd.parameters(), lr=1e-3)\n",
    "    params = {'model' : model.mrnd, \n",
    "        'criterion': loss_fn,  \n",
    "        'optimizer': optimizer, \n",
    "        'callbacks': [savebest,  ptt.PrintCallback()] #ptt.PlotCallback(),\n",
    "    }\n",
    "       \n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ptt.DeepNetTrainer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit_loader(num_epochs, dset_loaders_convnet['train'], dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mrnd = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    !free -h\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2save = './figures/results_metrics.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "metrics_map = {'losses': 'Loss', 'acc': 'Acuracy'}\n",
    "\n",
    "metrics_eval_nb = len(trainer.metrics['train'].keys())\n",
    "count = 1\n",
    "for metric in trainer.metrics['train'].keys():\n",
    "    plt.subplot(1,metrics_eval_nb, count)\n",
    "    plt.plot(trainer.metrics['train'][metric], 'o-b', label = 'train')\n",
    "    plt.plot(trainer.metrics['valid'][metric], 'o-r', label = 'valid')\n",
    "    count += 1\n",
    "    plt.xlabel('Epochs', fontsize = 12)\n",
    "    plt.ylabel(metrics_map[metric], fontsize = 12)\n",
    "    plt.title(metrics_map[metric] + \" during the model's training\", fontsize = 16)\n",
    "    plt.legend()\n",
    "fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = trainer.evaluate_loader(dset_loaders_convnet['train'])\n",
    "valid_eval = trainer.evaluate_loader(dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval, valid_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders_wshuffle = _create_dataLoader(dsets, batch_size, cpu_count, pin_memory=use_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = predict(dset_loaders_wshuffle['train'], model)\n",
    "result_valid = predict(dset_loaders_wshuffle['valid'], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(result_valid):\n",
    "    _, predicted = torch.max(result_valid, 1)\n",
    "    return predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2numpy(result):\n",
    "    return result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train['pred'] = getPrediction(result_train['pred'])\n",
    "result_valid['pred'] = getPrediction(result_valid['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train['pred'] = tensor2numpy(result_train['pred'])\n",
    "result_train['true'] = tensor2numpy(result_train['true'])\n",
    "\n",
    "result_valid['pred'] = tensor2numpy(result_valid['pred'])\n",
    "result_valid['true'] = tensor2numpy(result_valid['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = (result_train['true'] == result_train['pred']).sum()\n",
    "correct_valid = (result_valid['true'] == result_valid['pred']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: ', correct_train, '/', len(conv_dset['train']) )\n",
    "print('Valid: ', correct_valid, '/', len(conv_dset['valid']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_correct = np.where(result_train['true'] == result_train['pred'])[0]\n",
    "lst_incorrect = np.where(result_train['true'] != result_train['pred'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(dsets, lst, path2save = []):\n",
    "    maxSubPlot = 4\n",
    "    if len(lst)<4:\n",
    "        maxSubPlot = len(lst)\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    for i, j in enumerate(range(0,maxSubPlot)):\n",
    "        fig.add_subplot(1, maxSubPlot, i+1)\n",
    "        (inputs, output) = dsets[lst[j]]\n",
    "        img = denormalize(inputs.numpy())\n",
    "        img = np.clip(img, 0, 1.0)\n",
    "        plt.imshow(img)\n",
    "        #plt.title('{0} / {1}'.format(labels['c'+str(output)],  labels[('c'+str(result_train['pred'][lst[j]]))]))    \n",
    "        plt.title('{0} / {1}'.format(('c'+str(output)),  ('c'+str(result_train['pred'][lst[j]]))))    \n",
    "        plt.axis('off')\n",
    "    if len(path2save) !=0:\n",
    "        fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(dsets['train'], lst_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(dsets['train'], lst_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(results):\n",
    "    mc = np.array(pd.crosstab(results['pred'], results['true']))\n",
    "    plt.imshow(mc/mc.sum(axis=1))\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plot_confusion(result_train)\n",
    "plt.title('Train dataset')\n",
    "plt.subplot(1,2,2)\n",
    "plot_confusion(result_valid)\n",
    "plt.title('Valid dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layers_weight(img_width, img_height, conv_model = model.mrnc, ncols = 8, H = 14, W=30):\n",
    "\n",
    "\n",
    "    rand_idx = random.randrange(0, len(dsets['train']))\n",
    "    input, _ = dsets['train'][rand_idx]\n",
    "    input = input.view(1, 3, img_width, img_height)\n",
    "\n",
    "    if use_gpu:\n",
    "        x = Variable(input.cuda())\n",
    "    else:\n",
    "        x = Variable(input)\n",
    "\n",
    "\n",
    "    for name, layer in conv_model.named_children():\n",
    "        x = layer(x)\n",
    "        grid = torchvision.utils.make_grid(torch.transpose(x.data, 0, 1), normalize=True, \n",
    "                                           pad_value=1.0, padding=1).cpu().numpy()\n",
    "\n",
    "        if name == 'max_pool':\n",
    "            H /= 3/2\n",
    "            W /= 3/2\n",
    "        fig = plt.figure(figsize=(H,W))\n",
    "        plt.imshow(grid.transpose((1,2,0)))\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layers_weight(img_width=224, img_height=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
