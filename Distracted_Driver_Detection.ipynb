{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "from src.imgnet_utils import denormalize\n",
    "\n",
    "from src.data_loader import _create_dataLoader\n",
    "\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "\n",
    "from src.plot_utils import (plot_classes, plot_distribution,\n",
    "                            statistical_analysis_image, classDistribution,\n",
    "                            plot_metrics,visualize_predictions,\n",
    "                            plot_cm_train_valid,plot_layers_weight)\n",
    "      \n",
    "from src.convnet_models import (MyResNet, MyInception, MyDenseNet)\n",
    "from src.extractor_utils import (predict, getPrediction,save_prediction,\n",
    "                                 load_prediction, torch_summarize,RandomSearch)\n",
    "\n",
    "from utils.utils import (create_submission ,metrics2csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making results reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "seed=1719\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for resources avaliables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} GPU's available:\".format(torch.cuda.device_count()) )\n",
    "cpu_count = torch.multiprocessing.cpu_count()\n",
    "print(\"\\ncpu_count: {}\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "use_DataParalel= True\n",
    "use_CPU= False       \n",
    "\n",
    "if use_gpu:\n",
    "    if use_DataParalel: \n",
    "        print(\"Using DataParalel in all {} GPUS\".format(torch.cuda.device_count()))\n",
    "    else:\n",
    "        print('Using only one GPU') \n",
    "if use_CPU:         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "    print(\"Using {} CPU's\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Path to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2features= \"./features/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearch on hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to optimze hyperparameters\n",
    "hiper_tunning = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_resnet = False\n",
    "use_inception = False\n",
    "use_denseNet = True\n",
    "\n",
    "if use_resnet:\n",
    "    print('Using ResNet model')\n",
    "    model_name = \"ResNet\"\n",
    "    model = MyResNet()\n",
    "elif use_inception:\n",
    "    print('Using Inception model')\n",
    "    model_name = \"Inception\"\n",
    "    model = MyInception()\n",
    "elif use_denseNet:\n",
    "    print('Using DenseNet model')\n",
    "    model_name = \"DenseNet\"    \n",
    "    model = MyDenseNet()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    if use_DataParalel:\n",
    "        print(\"Using all GPU's \")\n",
    "        model.mrnc = torch.nn.DataParallel(model.mrnc) #device_ids=[1,3]\n",
    "        model.mrnc = model.mrnc.cuda()\n",
    "        model.mrnd = torch.nn.DataParallel(model.mrnd) #device_ids=[1,3]\n",
    "        model.mrnd = model.mrnd.cuda()\n",
    "    else:\n",
    "        print('Using GPU')# {}'.format(device_id))\n",
    "        model.cuda()\n",
    "else:\n",
    "    print(\"Using CPU's\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_feat= load_prediction(path2features,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_feat['train'][0].shape,load_feat['train'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dset ={\n",
    "'train': TensorDataset(load_feat['train'][0], load_feat['train'][1]),\n",
    "'valid': TensorDataset(load_feat['valid'][0], load_feat['valid'][1]),\n",
    "'test': TensorDataset(load_feat['test'][0], load_feat['test'][1])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "\n",
    "dset_loaders_convnet = _create_dataLoader(conv_dset, batch_size, \n",
    "                        pin_memory=False, use_shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_convnet_sizes = {x: len(dset_loaders_convnet[x]) for x in ['train','valid', 'test']} \n",
    "dset_convnet_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hiper_tunning: \n",
    "    model_name += 'RandomSearch' \n",
    "\n",
    "path2saveModel = './models/'+model_name+'DistractDriver' \n",
    "\n",
    "savebest = ptt.ModelCheckpoint(path2saveModel,reset=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer =  optim.Adam(model.mrnd.parameters(), lr=1e-3,weight_decay=0)\n",
    "\n",
    "params = {'model' : model.mrnd, \n",
    "    'criterion': loss_fn,  \n",
    "    'optimizer': optimizer, \n",
    "    'callbacks': [savebest, ptt.AccuracyMetric()] #ptt.PlotCallback(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space for tunning hyperparameters \n",
    "args= {'lr':[1e-5,1e-2],\n",
    "       'weight_decay':[1e-8,1e-3] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hiper_tunning: \n",
    "\n",
    "    output = RandomSearch(params,args,\n",
    "                          num_epochs=num_epochs,path2saveModel=path2saveModel,\n",
    "                          dset_loaders_convnet=dset_loaders_convnet,\n",
    "                          MAX_IT=20,verbose=1)\n",
    "    \n",
    "    trainer = output['best_trainer']\n",
    "    print('****************************')\n",
    "    print('\\nBest parameters {}'.format(output['best_parameters']))\n",
    "    print('\\nBest result {}'.format(output['best_result']))\n",
    "\n",
    "else:\n",
    "    params['callbacks'].append(ptt.PrintCallback())\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.55)\n",
    "    trainer = ptt.DeepNetTrainer(use_gpu=use_gpu,lr_scheduler=scheduler,**params)\n",
    "    trainer.fit_loader(num_epochs, dset_loaders_convnet['train'], dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch_summarize(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_state(path2saveModel)\n",
    "model.mrnd = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2csv(trainer, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = trainer.evaluate_loader(dset_loaders_convnet['train'])\n",
    "valid_eval = trainer.evaluate_loader(dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval, valid_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset without shuffling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilized to plot mismatch cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = \"/mnt/home/e209440/data/train\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img_width = img_height=300 #to use InceptionV3 it must img_width and img_height be changed to 300\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "use_only = 1.0 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'valid': KaggleSafeDriverDataset(path2train,\n",
    "                                     transforms=data_transforms['valid'],\n",
    "                                     use_only=use_only, is_val=True, val_size=0.2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dset_loaders_wshuffle = _create_dataLoader(dsets, batch_size,\n",
    "                                           pin_memory=False, use_shuffle= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating resultings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to use all dloader, because this one has use_shuffle false\n",
    "result_train = predict(dset_loaders_convnet['train'], model.mrnd, use_gpu=use_gpu)\n",
    "\n",
    "result_valid = predict(dset_loaders_wshuffle['valid'], model, use_gpu=use_gpu)\n",
    "\n",
    "result_test = predict(dset_loaders_convnet['test'], model.mrnd, use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_out = {'train': (result_train['pred'], result_train['true'], model_name),\n",
    "                   'valid': (result_valid['pred'], result_valid['true'], model_name),\n",
    "                   'test': (result_test['pred'], result_test['true'], model_name)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2results = './results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction(path2results,predictions_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = getPrediction(result_train)\n",
    "result_valid = getPrediction(result_valid)\n",
    "# result_test['pred'] must be an array of probabilities to make the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = (result_train['true'] == result_train['pred']).sum()\n",
    "correct_valid = (result_valid['true'] == result_valid['pred']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: ', correct_train, '/', '17940' )# len(dsets['train'])\n",
    "print('Valid: ', correct_valid, '/', '4484' ) # len(dsets['valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission of the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(result_test, model_name + '_distracted_driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
