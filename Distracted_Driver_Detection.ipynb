{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "from src.imgnet_utils import denormalize\n",
    "\n",
    "from src.data_loader import _create_dataLoader\n",
    "\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "\n",
    "from src.plot_utils import (plot_classes, plot_distribution,\n",
    "                            statistical_analysis_image, classDistribution,\n",
    "                            plot_metrics,visualize_predictions,\n",
    "                            plot_cm_train_valid,plot_layers_weight)\n",
    "      \n",
    "from src.convnet_models import (MyResNet, MyInception, MyDenseNet, MyVGG)\n",
    "from src.extractor_utils import (predict, getPrediction,features_saving,\n",
    "                                 features_loading, torch_summarize)\n",
    "\n",
    "from utils.utils import (create_submission ,metrics2csv, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for resources avaliables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           220G        194G        5.0G         10G         20G         14G\n",
      "Swap:            0B          0B          0B\n",
      "Sun Nov 26 23:40:43 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00003609:00:00.0 Off |                    0 |\n",
      "| N/A   60C    P0   134W / 149W |   7316MiB / 11439MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00004BDC:00:00.0 Off |                    0 |\n",
      "| N/A   83C    P0   105W / 149W |   8809MiB / 11439MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00006ABF:00:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    53W / 149W |    472MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00008660:00:00.0 Off |                    0 |\n",
      "| N/A   28C    P8    34W / 149W |     11MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     39219      C   /usr/local/bin/python3.6                    1152MiB |\n",
      "|    0    111302      C   /usr/local/bin/python3.6                    1160MiB |\n",
      "|    0    115413      C   /usr/local/bin/python3.6                     394MiB |\n",
      "|    0    121381      C   /usr/local/bin/python3.6                     367MiB |\n",
      "|    0    122583      C   /usr/local/bin/python3.6                       1MiB |\n",
      "|    0    129848      C   /usr/local/bin/python3.6                    2355MiB |\n",
      "|    1    121827      C   /usr/local/bin/python3.6                    8796MiB |\n",
      "|    2      1368      C   /usr/local/bin/python3.6                     461MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!free -h\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GPU's available:\n",
      "\n",
      "cpu_count: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"{} GPU's available:\".format(torch.cuda.device_count()) )\n",
    "cpu_count = torch.multiprocessing.cpu_count()\n",
    "print(\"\\ncpu_count: {}\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only one GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "use_DataParalel= False \n",
    "use_CPU= False       \n",
    "\n",
    "if use_gpu:\n",
    "    if use_DataParalel: \n",
    "        print(\"Using DataParalel in all {} GPUS\".format(torch.cuda.device_count()))\n",
    "    else:\n",
    "        print('Using only one GPU') \n",
    "if use_CPU:         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "    print(\"Using {} CPU's\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Path to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2features= \"./features/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ResNet model\n"
     ]
    }
   ],
   "source": [
    "use_resnet = True\n",
    "use_inception = False\n",
    "use_denseNet = False\n",
    "\n",
    "if use_resnet:\n",
    "    print('Using ResNet model')\n",
    "    model_name = \"ResNet\"\n",
    "    model = MyResNet()\n",
    "elif use_inception:\n",
    "    print('Using Inception model')\n",
    "    model_name = \"Inception\"\n",
    "    model = MyInception()\n",
    "elif use_denseNet:\n",
    "    print('Using DenseNet model')\n",
    "    model_name = \"DenseNet\"    \n",
    "    model = MyDenseNet()\n",
    "    \n",
    "elif use_VGG:\n",
    "    print('Using VGG model')\n",
    "    model_name = \"VGG\"    \n",
    "    model = MyVGG()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    if use_DataParalel:\n",
    "        print(\"Using all GPU's \")\n",
    "        model.mrnc = torch.nn.DataParallel(model.mrnc) #device_ids=[1,3]\n",
    "        model.mrnc = model.mrnc.cuda()\n",
    "        model.mrnd = torch.nn.DataParallel(model.mrnd) #device_ids=[1,3]\n",
    "        model.mrnd = model.mrnd.cuda()\n",
    "    else:\n",
    "        print('Using GPU')# {}'.format(device_id))\n",
    "        model.cuda()\n",
    "else:\n",
    "    print(\"Using CPU's\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features with shapes: \n",
      "\n",
      "\n",
      "train:\n",
      "pred torch.Size([17940, 6400]), true torch.Size([17940])\n",
      "\n",
      "valid:\n",
      "pred torch.Size([4484, 6400]), true torch.Size([4484])\n",
      "\n",
      "test:\n",
      "pred torch.Size([79726, 6400]), true torch.Size([79726])\n"
     ]
    }
   ],
   "source": [
    "load_feat= features_loading(path2features,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17940, 6400]), torch.Size([17940]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_feat['train'][0].shape,load_feat['train'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dset ={\n",
    "'train': TensorDataset(load_feat['train'][0], load_feat['train'][1]),\n",
    "'valid': TensorDataset(load_feat['valid'][0], load_feat['valid'][1]),\n",
    "'test': TensorDataset(load_feat['test'][0], load_feat['test'][1])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "\n",
    "dset_loaders_convnet = _create_dataLoader(conv_dset, batch_size, \n",
    "                        pin_memory=False, use_shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 2492, 'train': 561, 'valid': 141}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_convnet_sizes = {x: len(dset_loaders_convnet[x]) for x in ['train','valid', 'test']} \n",
    "dset_convnet_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2saveModel = './models/'+model_name+'DistractDriver' \n",
    "savebest = ptt.ModelCheckpoint(path2saveModel,reset=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_epochs = 70\n",
    "\n",
    "optimizer =  optim.Adam(model.mrnd.parameters(), lr=1e-3,weight_decay=0)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.55)\n",
    "\n",
    "params = {'model' : model.mrnd, \n",
    "    'criterion': loss_fn,  \n",
    "    'optimizer': optimizer, \n",
    "    'callbacks': [savebest, ptt.AccuracyMetric(), ptt.PrintCallback()] #ptt.PlotCallback(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ptt.DeepNetTrainer(use_gpu=use_gpu,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 70 epochs\n",
      "  1:  36.3s   T: 2.23244 0.18779   V: 1.32959 0.47569 best\n",
      "  2:  14.6s   T: 0.98976 0.62653   V: 0.45969 0.86062 best\n",
      "  3:  14.6s   T: 0.49378 0.82480   V: 0.30764 0.90299 best\n",
      "  4:  14.7s   T: 0.34106 0.88590   V: 0.25421 0.90745 best\n",
      "  5:  14.7s   T: 0.29950 0.89944   V: 0.13302 0.95852 best\n",
      "  6:  14.7s   T: 0.26380 0.91349   V: 0.13454 0.95919 \n",
      "  7:  14.7s   T: 0.21400 0.92938   V: 0.13481 0.95763 \n",
      "  8:  14.8s   T: 0.23064 0.92363   V: 0.26040 0.92730 \n",
      "  9:  14.7s   T: 0.23723 0.92090   V: 0.12595 0.96566 best\n",
      " 10:  14.5s   T: 0.28122 0.90139   V: 0.10935 0.96922 best\n",
      " 11:  14.5s   T: 0.21046 0.92988   V: 0.09464 0.97502 best\n",
      " 12:  14.4s   T: 0.24003 0.91957   V: 0.06506 0.98417 best\n",
      " 13:  14.7s   T: 0.25684 0.91382   V: 0.12538 0.96120 \n",
      " 14:  14.3s   T: 0.21879 0.92726   V: 0.04421 0.98773 best\n",
      " 15:  14.2s   T: 0.18784 0.93835   V: 0.12535 0.95874 \n",
      " 16:  13.9s   T: 0.17018 0.94387   V: 0.07405 0.98060 \n",
      " 17:  14.1s   T: 0.17611 0.93974   V: 0.06733 0.98060 \n",
      " 18:  12.2s   T: 0.16182 0.94677   V: 0.07226 0.97837 \n",
      " 19:   6.3s   T: 0.15251 0.95045   V: 0.06640 0.98127 \n",
      " 20:   6.0s   T: 0.14372 0.95290   V: 0.09650 0.97368 \n",
      " 21:   6.4s   T: 0.16550 0.94459   V: 0.19200 0.94826 \n",
      " 22:   7.2s   T: 0.17607 0.94192   V: 0.06094 0.98372 \n",
      " 23:  12.3s   T: 0.20868 0.93027   V: 0.04762 0.98818 \n",
      " 24:   6.0s   T: 0.18793 0.93763   V: 0.04527 0.98840 \n",
      " 25:   7.1s   T: 0.18697 0.93891   V: 0.06255 0.98350 \n",
      " 26:   8.0s   T: 0.17562 0.94147   V: 0.04824 0.98684 \n",
      " 27:  13.4s   T: 0.18512 0.93857   V: 0.05032 0.99019 \n",
      " 28:  14.7s   T: 0.17051 0.94253   V: 0.06178 0.98194 \n",
      " 29:  14.6s   T: 0.15720 0.94721   V: 0.06237 0.98149 \n",
      " 30:  14.6s   T: 0.16865 0.94303   V: 0.11412 0.96722 \n",
      " 31:  14.8s   T: 0.16330 0.94554   V: 0.03812 0.99086 best\n",
      " 32:  14.5s   T: 0.12428 0.95903   V: 0.04937 0.98662 \n",
      " 33:  14.7s   T: 0.14984 0.95223   V: 0.09683 0.97391 \n",
      " 34:  14.6s   T: 0.16287 0.94805   V: 0.05541 0.98506 \n",
      " 35:  14.5s   T: 0.15376 0.94738   V: 0.04699 0.98996 \n",
      " 36:  14.7s   T: 0.14246 0.95072   V: 0.06042 0.98417 \n",
      " 37:  14.7s   T: 0.22817 0.92235   V: 0.05019 0.98907 \n",
      " 38:  14.8s   T: 0.20607 0.92670   V: 0.04149 0.98930 \n",
      " 39:  14.6s   T: 0.19250 0.93428   V: 0.22241 0.92730 \n",
      " 40:  14.5s   T: 0.16902 0.94370   V: 0.09390 0.97257 \n",
      " 41:  14.5s   T: 0.16385 0.94415   V: 0.07666 0.98171 \n",
      " 42:  14.8s   T: 0.18892 0.93478   V: 0.03573 0.99019 best\n",
      " 43:  14.9s   T: 0.17643 0.93935   V: 0.03608 0.99197 \n",
      " 44:  14.5s   T: 0.15890 0.94443   V: 0.04566 0.98996 \n",
      " 45:  14.0s   T: 0.16369 0.94431   V: 0.03957 0.98996 \n",
      " 46:  13.8s   T: 0.16495 0.94487   V: 0.08584 0.97725 \n",
      " 47:   7.2s   T: 0.17260 0.94013   V: 0.09728 0.97079 \n",
      " 48:   6.0s   T: 0.16937 0.94158   V: 0.06163 0.98372 \n",
      " 49:   6.2s   T: 0.24556 0.91210   V: 0.09539 0.97881 \n",
      " 50:   7.3s   T: 0.19957 0.92798   V: 0.07369 0.98216 \n",
      " 51:  12.1s   T: 0.18373 0.93367   V: 0.11133 0.96699 \n",
      " 52:   6.1s   T: 0.25097 0.91226   V: 0.06931 0.98194 \n",
      " 53:   6.0s   T: 0.19424 0.92993   V: 0.05644 0.98506 \n",
      " 54:   6.0s   T: 0.19738 0.93038   V: 0.03769 0.99108 \n",
      " 55:  11.7s   T: 0.21567 0.92447   V: 0.11308 0.97034 \n",
      " 56:  14.4s   T: 0.18446 0.93517   V: 0.03767 0.99041 \n",
      " 57:  14.7s   T: 0.20137 0.93004   V: 0.03671 0.99197 \n",
      " 58:  14.7s   T: 0.18531 0.93406   V: 0.04506 0.98796 \n",
      " 59:  14.7s   T: 0.19767 0.93149   V: 0.06285 0.98506 \n",
      " 60:  14.7s   T: 0.20877 0.92497   V: 0.05219 0.98840 \n",
      " 61:  14.4s   T: 0.20130 0.93250   V: 0.04424 0.98863 \n",
      " 62:  14.7s   T: 0.17090 0.94086   V: 0.03597 0.99153 \n",
      " 63:  14.7s   T: 0.18296 0.93824   V: 0.14218 0.95027 \n",
      " 64:  14.7s   T: 0.17789 0.93952   V: 0.05578 0.99019 \n",
      " 65:  14.6s   T: 0.15648 0.94158   V: 0.05696 0.98617 \n",
      " 66:  14.8s   T: 0.16274 0.94298   V: 0.04144 0.99041 \n",
      " 67:  14.7s   T: 0.28546 0.89208   V: 0.05378 0.98461 \n",
      " 68:  14.8s   T: 0.25345 0.89894   V: 0.05714 0.98818 \n",
      " 69:  14.6s   T: 0.17915 0.93289   V: 0.07631 0.98305 \n",
      " 70:  14.5s   T: 0.14670 0.94827   V: 0.04191 0.99063 \n",
      "Best model was saved at epoch 42 with loss 0.03573: /mnt/home/e209440/models/ResNetDistractDriver\n",
      "Stop training at epoch: 70/70\n"
     ]
    }
   ],
   "source": [
    "trainer.fit_loader(num_epochs, dset_loaders_convnet['train'], dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyResNet (\n",
      "  (mrnc): MyResNetConv (\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu): ReLU (inplace)\n",
      "    (maxpool): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "    (layer1): Sequential (\n",
      "      (0): BasicBlock (\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "      (1): BasicBlock (\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential (\n",
      "      (0): BasicBlock (\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (downsample): Sequential (\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock (\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential (\n",
      "      (0): BasicBlock (\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (downsample): Sequential (\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock (\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential (\n",
      "      (0): BasicBlock (\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (downsample): Sequential (\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock (\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AvgPool2d (size=7, stride=7, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  ), parameters=11176512\n",
      "  (mrnd): MyResNetDens (\n",
      "    (dens1): Linear (6400 -> 512)\n",
      "    (dens2): Linear (512 -> 128)\n",
      "    (dens3): Linear (128 -> 10)\n",
      "  ), parameters=3344266\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch_summarize(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_state(path2saveModel)\n",
    "model.mrnd = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "metrics2csv(trainer, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate: 560/560 ok\n",
      "evaluate: 140/140 ok\n"
     ]
    }
   ],
   "source": [
    "train_eval = trainer.evaluate_loader(dset_loaders_convnet['train'])\n",
    "valid_eval = trainer.evaluate_loader(dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'losses': 0.013342254084750772}, {'losses': 0.03572719438495006})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval, valid_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset without shuffling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilized to plot mismatch cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = \"/mnt/home/e209440/data/train\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img_width = img_height=300 #to use InceptionV3 it must img_width and img_height be changed to 300\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "use_only = 1.0 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'valid': KaggleSafeDriverDataset(path2train,\n",
    "                                     transforms=data_transforms['valid'],\n",
    "                                     use_only=use_only, is_val=True, val_size=0.2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dset_loaders_wshuffle = _create_dataLoader(dsets, batch_size,\n",
    "                                           pin_memory=False, use_shuffle= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating resultings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 560/560 ok\n",
      "predict: 140/140 ok\n",
      "predict: 2491/2491 ok\n"
     ]
    }
   ],
   "source": [
    "#we need to use all dloader, because this one has use_shuffle false\n",
    "result_train = predict(dset_loaders_convnet['train'], model.mrnd, use_gpu=use_gpu)\n",
    "\n",
    "result_valid = predict(dset_loaders_wshuffle['valid'], model, use_gpu=use_gpu)\n",
    "\n",
    "result_test = predict(dset_loaders_convnet['test'], model.mrnd, use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_out = {'train': result_train, 'valid': result_valid, 'test': result_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set result saved!\n",
      "valid set result saved!\n",
      "test set result saved!\n"
     ]
    }
   ],
   "source": [
    "save_results(predictions_out, model_name,use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = getPrediction(result_train)\n",
    "result_valid = getPrediction(result_valid)\n",
    "# result_test['pred'] must be an array of probabilities to make the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = (result_train['true'] == result_train['pred']).sum()\n",
    "correct_valid = (result_valid['true'] == result_valid['pred']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  17879 / 17940\n",
      "Valid:  4438 / 4484\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', correct_train, '/', '17940' )# len(dsets['train'])\n",
    "print('Valid: ', correct_valid, '/', '4484' ) # len(dsets['valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission of the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "create_submission(result_test, model_name + '_distracted_driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
