{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "from src.imgnet_utils import denormalize\n",
    "\n",
    "from src.data_loader import _create_dataLoader\n",
    "\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "\n",
    "from src.plot_utils import (plot_classes, plot_distribution,\n",
    "                            statistical_analysis_image, classDistribution,\n",
    "                            plot_metrics,visualize_predictions,\n",
    "                            plot_cm_train_valid,plot_layers_weight)\n",
    "      \n",
    "from src.convnet_models import (MyResNet, MyInception, MyDenseNet)\n",
    "\n",
    "from src.extractor_utils import (predict, getPrediction)\n",
    "\n",
    "from utils.make_submission import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GPU's available:\n",
      "\n",
      "cpu_count: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"{} GPU's available:\".format(torch.cuda.device_count()) )\n",
    "cpu_count = torch.multiprocessing.cpu_count()\n",
    "print(\"\\ncpu_count: {}\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataParalel in all 4 GPUS\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "use_DataParalel= True # Need some improvement on model's to work properly, basically it has to wrap all models block:\n",
    "use_CPU= False         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "\n",
    "if use_gpu:\n",
    "    if use_DataParalel: \n",
    "        print(\"Using DataParalel in all {} GPUS\".format(torch.cuda.device_count()))\n",
    "    else:\n",
    "        print('Using only one GPU') #{} '.format(device_id))\n",
    "if use_CPU:         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "    print(\"Using {} CPU's\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           220G         51G         99G        566M         69G        166G\n",
      "Swap:            0B          0B          0B\n",
      "Sat Nov 25 11:51:13 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00003609:00:00.0 Off |                    0 |\n",
      "| N/A   63C    P0   129W / 149W |   6705MiB / 11439MiB |      4%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00004BDC:00:00.0 Off |                    0 |\n",
      "| N/A   69C    P0    60W / 149W |   2144MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00006ABF:00:00.0 Off |                    0 |\n",
      "| N/A   68C    P0   142W / 149W |   6923MiB / 11439MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00008660:00:00.0 Off |                    0 |\n",
      "| N/A   26C    P8    34W / 149W |     11MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     29514      C   /usr/local/bin/python3.6                    1152MiB |\n",
      "|    0     33102      C   /usr/local/bin/python3.6                     195MiB |\n",
      "|    0     38585      C   /usr/local/bin/python3.6                    1986MiB |\n",
      "|    0    118292      C   /usr/local/bin/python3.6                     453MiB |\n",
      "|    0    126138      C   /usr/local/bin/python3.6                    2011MiB |\n",
      "|    1     33102      C   /usr/local/bin/python3.6                    2133MiB |\n",
      "|    2    109422      C   /usr/local/bin/python3.6                    6912MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    !free -h\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Choose dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = \"/mnt/home/e209440/data/train\" \n",
    "path2test = \"/mnt/home/e209440/data/test\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img_width = img_height=300 #to use InceptionV3 it must img_width and img_height be changed to 300\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating  Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "use_only = 0.1 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'train': KaggleSafeDriverDataset(path2train, transforms=data_transforms['train'],use_only=use_only),\n",
    "    'valid': KaggleSafeDriverDataset(path2train, transforms=data_transforms['valid'],use_only=use_only, is_val=True, val_size=0.2),\n",
    "    'test':  KaggleSafeDriverDataset(path2test, transforms=data_transforms['valid'],use_only=use_only, is_test=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = _create_dataLoader(dsets, batch_size, pin_memory=False, use_shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794, {'test': 7972, 'train': 1794, 'valid': 448})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['train','valid', 'test']} \n",
    "dset_classes = len(dsets['train'].y)\n",
    "dset_classes, dset_sizes\n",
    "\n",
    "# Dataset have much more samples than datatrain ***It comes from the test.zip****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           220G         51G         99G        566M         69G        166G\n",
      "Swap:            0B          0B          0B\n",
      "Sat Nov 25 11:51:29 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00003609:00:00.0 Off |                    0 |\n",
      "| N/A   62C    P0   140W / 149W |   6705MiB / 11439MiB |     42%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00004BDC:00:00.0 Off |                    0 |\n",
      "| N/A   69C    P0    60W / 149W |   2144MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00006ABF:00:00.0 Off |                    0 |\n",
      "| N/A   68C    P0    90W / 149W |   6923MiB / 11439MiB |     26%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00008660:00:00.0 Off |                    0 |\n",
      "| N/A   26C    P8    34W / 149W |     11MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     29514      C   /usr/local/bin/python3.6                    1152MiB |\n",
      "|    0     33102      C   /usr/local/bin/python3.6                     195MiB |\n",
      "|    0     38585      C   /usr/local/bin/python3.6                    1986MiB |\n",
      "|    0    118292      C   /usr/local/bin/python3.6                     453MiB |\n",
      "|    0    126138      C   /usr/local/bin/python3.6                    2011MiB |\n",
      "|    1     33102      C   /usr/local/bin/python3.6                    2133MiB |\n",
      "|    2    109422      C   /usr/local/bin/python3.6                    6912MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!free -h\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ResNet model\n"
     ]
    }
   ],
   "source": [
    "use_resnet = True\n",
    "use_inception = False\n",
    "use_denseNet = False\n",
    "\n",
    "if use_resnet:\n",
    "    print('Using ResNet model')\n",
    "    model = MyResNet()\n",
    "elif use_inception:\n",
    "    print('Using Inception model')\n",
    "    model = MyInception()\n",
    "elif use_denseNet:\n",
    "    print('Using DenseNet model')    \n",
    "    model = MyDenseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    print('Using GPU')# {}'.format(device_id))\n",
    "    model.cuda()\n",
    "    convnet = model.mrnc\n",
    "    densenet = model.mrnd\n",
    "    \n",
    "elif use_DataParalel:\n",
    "    print(\"Using all GPU's \")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "    convnet = model.module.mrnc\n",
    "    densenet = model.module.mrnd\n",
    "else:\n",
    "    convnet = model.mrnc\n",
    "    densenet = model.mrnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 56/56 ok\n",
      "predict: 13/13 ok\n",
      "predict: 249/249 ok\n"
     ]
    }
   ],
   "source": [
    "#extract features from images\n",
    "convOutput_train = predict(dset_loaders['train'], convnet,use_gpu=use_gpu)\n",
    "convOutput_valid = predict(dset_loaders['valid'], convnet,use_gpu=use_gpu)\n",
    "convOutput_test = predict(dset_loaders['test'], convnet,use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1794]) torch.Size([1794, 6400])\n",
      "torch.Size([448]) torch.Size([448, 6400])\n",
      "torch.Size([7972]) torch.Size([7972, 6400])\n"
     ]
    }
   ],
   "source": [
    "print(convOutput_train['true'].size(), convOutput_train['pred'].size())\n",
    "print(convOutput_valid['true'].size(), convOutput_valid['pred'].size())\n",
    "print(convOutput_test['true'].size(), convOutput_test['pred'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.LongTensor torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(convOutput_train['true'].type(), convOutput_train['pred'].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dset ={\n",
    "    'train': TensorDataset(convOutput_train['pred'], convOutput_train['true']),\n",
    "    'valid': TensorDataset(convOutput_valid['pred'], convOutput_valid['true']),\n",
    "    'test': TensorDataset(convOutput_test['pred'], convOutput_test['true'])\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders_convnet = _create_dataLoader(conv_dset, batch_size, \n",
    "                        pin_memory=False, use_shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 250, 'train': 57, 'valid': 14}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_convnet_sizes = {x: len(dset_loaders_convnet[x]) for x in ['train','valid', 'test']} \n",
    "dset_convnet_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels):\n",
    "    _, preds = torch.max(logits.data, 1)\n",
    "    return torch.sum(preds == labels.data) / labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2saveModel = '/mnt/home/r120084/project/models/distractdriver'\n",
    "#path2saveModel = '/mnt/home/e209440/models/ResNetDistractDriver' \n",
    "\n",
    "savebest = ptt.ModelCheckpoint(path2saveModel,reset=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_epochs = 50\n",
    "\n",
    "optimizer =  optim.Adam(densenet.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.75)\n",
    "metrics = dict(acc=compute_accuracy)\n",
    "\n",
    "params = {'model' : densenet, \n",
    "    'criterion': loss_fn,  \n",
    "    'metrics': metrics, \n",
    "    'optimizer': optimizer, \n",
    "    'callbacks': [savebest,  ptt.PrintCallback()] #ptt.PlotCallback(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3fc71b5b75a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepNetTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'metrics'"
     ]
    }
   ],
   "source": [
    "trainer = ptt.DeepNetTrainer(use_gpu=use_gpu,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 50 epochs\n",
      "  1:  25.2s   T: 1.66269   V: 0.55486 best\n",
      "  2:  12.3s   T: 0.39758   V: 0.32263 best\n",
      "  3:  12.5s   T: 0.23267   V: 0.60291 \n",
      "  4:  12.4s   T: 0.19890   V: 0.24328 best\n",
      "  5:  12.4s   T: 0.14350   V: 0.25054 \n",
      "  6:  12.4s   T: 0.14992   V: 0.33450 \n",
      "  7:  12.6s   T: 0.09498   V: 0.28285 \n",
      "  8:  12.5s   T: 0.12788   V: 0.18683 best\n",
      "  9:  12.1s   T: 0.10371   V: 0.31989 \n",
      " 10:  12.4s   T: 0.09722   V: 0.27857 \n",
      " 11:  12.1s   T: 0.08032   V: 0.05275 best\n",
      " 12:  12.2s   T: 0.07264   V: 0.04699 best\n",
      " 13:  12.2s   T: 0.06474   V: 0.35075 \n",
      " 14:  10.2s   T: 0.08937   V: 0.04275 best\n",
      " 15:   9.7s   T: 0.08375   V: 0.02636 best\n",
      " 16:  10.5s   T: 0.10195   V: 0.03329 \n",
      " 17:  10.7s   T: 0.05808   V: 0.03862 \n",
      " 18:  10.7s   T: 0.05387   V: 0.06939 \n",
      " 19:  10.8s   T: 0.04675   V: 0.15205 \n",
      " 20:  10.5s   T: 0.04743   V: 0.18609 \n",
      " 21:  10.6s   T: 0.08496   V: 0.03323 \n",
      " 22:  11.3s   T: 0.02672   V: 0.03459 \n",
      " 23:  12.2s   T: 0.03716   V: 0.15495 \n",
      " 24:  12.3s   T: 0.05447   V: 0.02202 best\n",
      " 25:  12.2s   T: 0.07383   V: 0.03418 \n",
      " 26:  12.2s   T: 0.02855   V: 0.03575 \n",
      " 27:  12.1s   T: 0.03529   V: 0.02884 \n",
      " 28:  12.3s   T: 0.04300   V: 0.07184 \n",
      " 29:  11.8s   T: 0.05632   V: 0.06608 \n",
      " 30:  12.1s   T: 0.02242   V: 0.01972 best\n",
      " 31:  12.1s   T: 0.03636   V: 0.08579 \n",
      " 32:  12.2s   T: 0.03677   V: 0.03657 \n",
      " 33:  12.2s   T: 0.05302   V: 0.16175 \n",
      " 34:  12.3s   T: 0.03318   V: 0.07452 \n",
      " 35:  11.9s   T: 0.01984   V: 0.02347 \n",
      " 36:  12.2s   T: 0.04276   V: 0.12641 \n",
      " 37:  12.2s   T: 0.06133   V: 0.03147 \n",
      " 38:  12.1s   T: 0.00677   V: 0.03477 \n",
      " 39:  12.3s   T: 0.01474   V: 0.13289 \n",
      " 40:  12.2s   T: 0.07151   V: 0.02381 \n",
      " 41:  12.0s   T: 0.01045   V: 0.04616 \n",
      " 42:  11.4s   T: 0.03971   V: 0.02106 \n",
      " 43:  10.5s   T: 0.04438   V: 0.02853 \n",
      " 44:  10.8s   T: 0.01338   V: 0.01567 best\n",
      " 45:  10.5s   T: 0.05293   V: 0.02183 \n",
      " 46:  10.7s   T: 0.00503   V: 0.03092 \n",
      " 47:   6.9s   T: 0.03277   V: 0.01608 \n",
      " 48:   7.2s   T: 0.03994   V: 0.03569 \n",
      " 49:   6.9s   T: 0.00787   V: 0.02186 \n",
      " 50:   7.1s   T: 0.05997   V: 0.04300 \n",
      "Best model was saved at epoch 44 with loss 0.01567: /mnt/home/r120084/project/models/distractdriver\n",
      "Stop training at epoch: 50/50\n"
     ]
    }
   ],
   "source": [
    "trainer.fit_loader(num_epochs, dset_loaders_convnet['train'], dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_state(path2saveModel)\n",
    "densenet = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           220G         52G        102G        571M         65G        165G\n",
      "Swap:            0B          0B          0B\n",
      "Sat Nov 25 10:43:47 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00003609:00:00.0 Off |                    0 |\n",
      "| N/A   65C    P0   139W / 149W |   8688MiB / 11439MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00004BDC:00:00.0 Off |                    0 |\n",
      "| N/A   70C    P0    60W / 149W |   2144MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00006ABF:00:00.0 Off |                    0 |\n",
      "| N/A   68C    P0    57W / 149W |   6923MiB / 11439MiB |     48%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00008660:00:00.0 Off |                    0 |\n",
      "| N/A   26C    P8    34W / 149W |     11MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     29514      C   /usr/local/bin/python3.6                    1152MiB |\n",
      "|    0     33102      C   /usr/local/bin/python3.6                     195MiB |\n",
      "|    0     38585      C   /usr/local/bin/python3.6                    1986MiB |\n",
      "|    0    118292      C   /usr/local/bin/python3.6                     453MiB |\n",
      "|    0    123337      C   /usr/local/bin/python3.6                    2296MiB |\n",
      "|    0    123517      C   /usr/local/bin/python3.6                    1697MiB |\n",
      "|    1     33102      C   /usr/local/bin/python3.6                    2133MiB |\n",
      "|    2    109422      C   /usr/local/bin/python3.6                    6912MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!free -h\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_metrics(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate: 560/560 ok\n",
      "evaluate: 140/140 ok\n"
     ]
    }
   ],
   "source": [
    "train_eval = trainer.evaluate_loader(dset_loaders_convnet['train'])\n",
    "valid_eval = trainer.evaluate_loader(dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'losses': 0.00108448752059527}, {'losses': 0.01567110304955815})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval, valid_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get output of the trained model (only denset)\n",
    "result_train = predict(dset_loaders_convnet['train'], densenet,use_gpu=use_gpu)\n",
    "result_valid = predict(dset_loaders_convnet['valid'], densenet,use_gpu=use_gpu)\n",
    "result_test = predict(dset_loaders_convnet['test'], densenet,use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = getPrediction(result_train)\n",
    "result_valid = getPrediction(result_valid)\n",
    "# result_test['pred'] must be an array of probabilities to make the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = (result_train['true'] == result_train['pred']).sum()\n",
    "correct_valid = (result_valid['true'] == result_valid['pred']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: ', correct_train, '/', len(conv_dset['train']) )\n",
    "print('Valid: ', correct_valid, '/', len(conv_dset['valid']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_predictions(dsets['valid'], result_valid, correct_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_predictions(dsets['valid'], result_valid, correct_pred = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_cm_train_valid(result_train,result_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_layers_weight(dsets,img_width=img_width, img_height=img_height,conv_model = model.mrnc,use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission of the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(result_test, 'distracted_driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
