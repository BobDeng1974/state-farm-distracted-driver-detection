{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os, glob, math,time\n",
    "#import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "#torch.multiprocessing.set_start_method(\"forkserver\")\n",
    "\n",
    "import torch as tc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "sys.path.append('/mnt/home/r120084/')\n",
    "sys.path.append('/home/r120084/pytorch_lib/pytorch')\n",
    "import lib.pytorch_trainer as ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "cpu_count:  24\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "cpu_count = 24 #torch.multiprocessing.cpu_count()\n",
    "\n",
    "print('GPU available:', use_gpu)\n",
    "print('cpu_count: ', cpu_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Choose dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_gpu=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nelse:\\n    path2train = \"/home/r120084/project/data/train\" #server without gpu\\n    path2test = \"/home/r120084/project/data/test\"\\n    \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if use_gpu:\n",
    "path2train = \"/mnt/home/e209440/data/train\" # with gpu \n",
    "path2test = \"/mnt/home/e209440/data/test\" \n",
    "'''\n",
    "else:\n",
    "    path2train = \"/home/r120084/project/data/train\" #server without gpu\n",
    "    path2test = \"/home/r120084/project/data/test\"\n",
    "    \n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {  'c0' : 'safe driving', \n",
    "            'c1' : 'texting - right', \n",
    "            'c2' : 'talking on the phone - right', \n",
    "            'c3' : 'texting - left', \n",
    "            'c4' : 'talking on the phone - left', \n",
    "            'c5' : 'operating the radio', \n",
    "            'c6' : 'drinking', \n",
    "            'c7' : 'reaching behind', \n",
    "            'c8' : 'hair and makeup', \n",
    "            'c9' : 'talking to passenger'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class with split data and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleSafeDriverDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        path: Path to data (train or test) \n",
    "        use_only: Percentage of total data that will be used.\n",
    "        transforms: PIL transforms to be perfomed on each item of get_item method\n",
    "        is_test: Test data (boolean)\n",
    "        is_val: Validation data (boolean)\n",
    "        val_size: Size of validation data \n",
    "        \n",
    "        **** The indices of Validation and Train dataset are shuffled****\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, use_only =1.0, transforms=None, \\\n",
    "                 is_test=False,is_val=False,val_size=0.2):\n",
    "    \n",
    "        self.transform = transforms        \n",
    "        \n",
    "        if is_test:\n",
    "\n",
    "            X_test    = []\n",
    "            path  = os.path.join(path, '*.jpg')\n",
    "            files = glob.glob(path)\n",
    "            X_test.extend(files)  \n",
    "\n",
    "            length = len(X_test)\n",
    "            only = int(use_only * length)\n",
    "            self.X = X_test[:only]\n",
    "            \n",
    "            self.y = None # In order to create the Dataloader of test data it has to have a y coordenate.\n",
    "        \n",
    "        else:\n",
    "\n",
    "            X_train= []\n",
    "            y_train = []\n",
    "            for i, label in enumerate(labels):\n",
    "                path_folder = os.path.join(path, str(label), '*.jpg')\n",
    "                files = glob.glob(path_folder) \n",
    "                X_train.extend(files)\n",
    "                y_train.extend([int(label[-1])]*len(files))\n",
    "\n",
    "            length = len(X_train)\n",
    "            indices = np.array((range(0,length)))\n",
    "            \n",
    "            nr.seed(4572)\n",
    "            ind = nr.permutation(indices)\n",
    "            \n",
    "            \n",
    "            length = ind.shape[0]\n",
    "            only = int(use_only * length)\n",
    "            \n",
    "            ind = ind[:only]\n",
    "            length = ind.shape[0]\n",
    "                 \n",
    "            split = int(val_size * length)\n",
    "            \n",
    "            if is_val:\n",
    "                self.X = [X_train[i] for i in ind[:split]]\n",
    "                self.y = [y_train[i] for i in ind[:split]]\n",
    " \n",
    "            else:\n",
    "                self.X = [X_train[i] for i in ind[split:]]\n",
    "                self.y = [y_train[i] for i in ind[split:]]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.X[index]\n",
    "        label = self.y[index]\n",
    "        with open(path, 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                 image = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 320\n",
    "img_size ,img_width, img_height = 224, 224, 224\n",
    "use_only = 0.5 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_transforms(img, img_width=img_width, img_height=img_height):\n",
    "    return img.resize((img_width, img_height))\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def denormalize(image, mean=imagenet_mean, std=imagenet_std):\n",
    "    inp = image.transpose((1, 2, 0))  # Channel Last\n",
    "    img = std * inp + mean\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#        transforms.RandomHorizontalFlip(), First try withouth Data Augmentation \n",
    "        transforms.Lambda(my_transforms),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Lambda(my_transforms),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'train': KaggleSafeDriverDataset(path2train, transforms=data_transforms['train'],use_only=use_only),\n",
    "    'valid': KaggleSafeDriverDataset(path2train, transforms=data_transforms['valid'],use_only=use_only, is_val=True, val_size=0.2),\n",
    "    'test':  KaggleSafeDriverDataset(path2test, transforms=data_transforms['valid'],use_only=use_only, is_test=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndset_loaders = {\\n    'train': torch.utils.data.DataLoader(dsets['train'], batch_size,num_workers=4, pin_memory=use_gpu, shuffle=True),\\n    'valid': torch.utils.data.DataLoader(dsets['valid'], batch_size,num_workers=4, pin_memory=use_gpu, shuffle=True),\\n    'test':  torch.utils.data.DataLoader(dsets['test'],  batch_size,num_workers=4, pin_memory=use_gpu, shuffle=False),\\n}\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "dset_loaders = {\n",
    "    'train': torch.utils.data.DataLoader(dsets['train'], batch_size,num_workers=4, pin_memory=use_gpu, shuffle=True),\n",
    "    'valid': torch.utils.data.DataLoader(dsets['valid'], batch_size,num_workers=4, pin_memory=use_gpu, shuffle=True),\n",
    "    'test':  torch.utils.data.DataLoader(dsets['test'],  batch_size,num_workers=4, pin_memory=use_gpu, shuffle=False),\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _create_dataLoader(dsets, batch_size, cpu_count, pin_memory =  False, shuffle = True):\n",
    "    dset_loaders = {}\n",
    "    for key in dsets.keys():\n",
    "        dset_loaders[key] = DataLoader(dsets[key], batch_size=batch_size, shuffle=shuffle, num_workers= cpu_count, pin_memory=pin_memory)\n",
    "\n",
    "    return dset_loaders\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = _create_dataLoader(dsets, batch_size, 1, pin_memory=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, {'test': 39863, 'train': 8970, 'valid': 2242})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['train','valid', 'test']} \n",
    "dset_classes = len(dsets['train'].y)\n",
    "dset_classes, dset_sizes\n",
    "\n",
    "# Datates has much more samples than datatrain ***It comes from the test.zip****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) 2.640000104904175 -2.1179039478302 torch.Size([320])\n"
     ]
    }
   ],
   "source": [
    "inputs,cls = next(iter(dset_loaders['train']))\n",
    "print(inputs[10].shape, inputs[10].max(), inputs[10].min(), cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classes(dset_loaders, labels, path2save = './figures/data.png'):\n",
    "\n",
    "    # Get a batch of training data\n",
    "    inputs, cls = next(iter(dset_loaders))\n",
    "    print(inputs[8].shape, cls.shape)\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    for i, j in enumerate(range(0,10)):\n",
    "        fig.add_subplot(2,5, i+1)\n",
    "        img = denormalize(inputs.numpy()[j])\n",
    "        img = np.clip(img, 0, 1.0)\n",
    "        plt.imshow(img)\n",
    "        plt.title('{}'.format(labels['c'+str(cls[j])]))\n",
    "        plt.axis('off')\n",
    "    fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(dset_loaders['train'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(img):\n",
    "    \n",
    "    if img.shape[2] != 3:\n",
    "        img = img.transpose((1, 2, 0))\n",
    "        \n",
    "    color_lst = ['red', 'green', 'blue']\n",
    "    for i in range(0, img.shape[2]):\n",
    "        c1=img[:,:,i].reshape(-1)\n",
    "        plt.hist(c1, 50, facecolor=color_lst[i], label = color_lst[i])\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis_image(dset_loaders, labels, path2save = './figures/distribution.png'):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    inputs, cls = next(iter(dset_loaders))\n",
    "    rand_idx = random.randrange(0, len(inputs))\n",
    "    img = inputs.numpy()[rand_idx]\n",
    "    img_denorm = denormalize(img)\n",
    "    plt.subplot(2,2,2)\n",
    "    plot_distribution(img_denorm)\n",
    "    plt.title('Image RGB after denormalization')\n",
    "    plt.subplot(2,2,4)\n",
    "    plot_distribution(img)\n",
    "    plt.title('Image RGB normalization')\n",
    "    plt.subplot(1,2,1)\n",
    "    img_denorm = np.clip(img_denorm, 0, 1.0)\n",
    "    plt.imshow(img_denorm)\n",
    "    plt.title('{}'.format(labels['c'+str(cls[rand_idx])]))\n",
    "    plt.axis('off')\n",
    "    fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_analysis_image(dset_loaders['train'], labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def code2label(dataset, labels): \n",
    "    class_str = []\n",
    "    for item in dataset.y:\n",
    "        class_str.append(labels['c'+str(item)])  \n",
    "    return class_str           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_str = code2label(dsets['train'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "sns.countplot(y=class_str, palette=\"Greens_d\");\n",
    "plt.xlabel(\"Classes\", fontsize=12)\n",
    "plt.ylabel('Counts', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Classes Distribution\", fontsize=15)\n",
    "plt.show()\n",
    "path2save = './figures/distribution_classes.png'\n",
    "fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_out = len(set(class_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myInception(torchvision.models.Inception3):\n",
    "    def __init__(self, fixed_extractor = True):\n",
    "        super().__init__(torchvision.models.inception_v3(pretrained=True))\n",
    "        self.load_state_dict(torch.utils.model_zoo.load_url(\n",
    "            'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth)'))\n",
    "        \n",
    "        if fixed_extractor:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dens1 = torch.nn.Linear(in_features=64, out_features=32)\n",
    "        self.dens2 = torch.nn.Linear(in_features=32, out_features=nb_out)\n",
    "    def forward(self, x):\n",
    "        x = self.dens1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dens2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mrnc = Inception()\n",
    "        self.mrnd = Classifier()\n",
    "    def forward(self, x):\n",
    "        x = self.mrnc(x)\n",
    "        x = self.mrnd(x)\n",
    "        return x \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNetConv(torchvision.models.ResNet):\n",
    "    def __init__(self, fixed_extractor = True):\n",
    "        super().__init__(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2])\n",
    "        self.load_state_dict(torch.utils.model_zoo.load_url(\n",
    "            'https://download.pytorch.org/models/resnet18-5c106cde.pth'))\n",
    "        \n",
    "        del self.fc\n",
    "        \n",
    "        if fixed_extractor:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class MyResNetDens(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dens1 = torch.nn.Linear(in_features=4096, out_features=512)\n",
    "        self.dens2 = torch.nn.Linear(in_features=512, out_features=128)\n",
    "        self.dens3 = torch.nn.Linear(in_features=128, out_features=nb_out)\n",
    "    def forward(self, x):\n",
    "        x = self.dens1(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dens2(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.dens3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MyResNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mrnc = MyResNetConv()\n",
    "        self.mrnd = MyResNetDens()\n",
    "    def forward(self, x):\n",
    "        x = self.mrnc(x)\n",
    "        x = self.mrnd(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando disponibilidade de recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           220G         15G        150G        1.7G         53G        200G\n",
      "Swap:            0B          0B          0B\n",
      "Tue Nov 14 23:32:13 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00003609:00:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    72W / 149W |   6400MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00004BDC:00:00.0 Off |                    0 |\n",
      "| N/A   41C    P8    26W / 149W |     11MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00006ABF:00:00.0 Off |                    0 |\n",
      "| N/A   30C    P8    26W / 149W |     11MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00008660:00:00.0 Off |                    0 |\n",
      "| N/A   25C    P8    33W / 149W |     11MiB / 11439MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     55948      C   /usr/local/bin/python3.6                     635MiB |\n",
      "|    0     66472      C   /usr/local/bin/python3.6                    4399MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "use_resnet = True\n",
    "\n",
    "if use_resnet:\n",
    "    model = MyResNet()\n",
    "else:\n",
    "    model = myInception()\n",
    "\n",
    "if use_gpu:\n",
    "    !free -h\n",
    "    !nvidia-smi\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dset_loaders, model):\n",
    "\n",
    "    predictions = []\n",
    "    labels_lst = []\n",
    "    ii_n = len(dset_loaders)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dset_loaders):\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        inputs = Variable(inputs)\n",
    "        predictions.append(model(inputs).data)\n",
    "        labels_lst.append(labels)\n",
    "\n",
    "        print('\\rpredict: {}/{}'.format(i, ii_n - 1), end='')\n",
    "    print(' ok')\n",
    "    if len(predictions) > 0:\n",
    "        return {'pred': torch.cat(predictions, 0), 'true':torch.cat(labels_lst, 0) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 28/28 ok\n",
      "predict: 7/7 ok\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    convOutput_train = predict(dset_loaders['train'], model.module.mrnc)\n",
    "    convOutput_valid = predict(dset_loaders['valid'], model.module.mrnc)\n",
    "else:\n",
    "    convOutput_train = predict(dset_loaders['train'], model.mrnc)\n",
    "    convOutput_valid = predict(dset_loaders['valid'], model.mrnc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8970]) torch.Size([8970, 4096])\n",
      "torch.Size([2242]) torch.Size([2242, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(convOutput_train['true'].size(), convOutput_train['pred'].size())\n",
    "print(convOutput_valid['true'].size(), convOutput_valid['pred'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.LongTensor torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(convOutput_train['true'].type(), convOutput_train['pred'].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dset ={\n",
    "    'train': TensorDataset(convOutput_train['pred'], convOutput_train['true']),\n",
    "    'valid': TensorDataset(convOutput_valid['pred'], convOutput_valid['true'])\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders_convnet = {\n",
    "    'train': torch.utils.data.DataLoader(conv_dset['train'], 320,  shuffle=False),\n",
    "    'valid': torch.utils.data.DataLoader(conv_dset['valid'], 320, shuffle=False)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset_loaders_convnet = _create_dataLoader(conv_dset, batch_size, cpu_count, pin_memory=use_gpu, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset_loaders_convnet['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path2saveModel = '/home/r120084/project/models/distractdriver'\n",
    "path2saveModel = '/mnt/home/e209440/models/ResNetDistractDriver' \n",
    "\n",
    "if use_gpu:    \n",
    " #   path2saveModel = '/mnt/home/r120084/project/models/distractdriver' \n",
    "    path2saveModel = '/mnt/home/e209440/models/ResNetDistractDriver' \n",
    "    \n",
    "savebest = ptt.ModelCheckpoint(path2saveModel,reset=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "num_epochs = 50\n",
    "\n",
    "if use_gpu:\n",
    "    optimizer =  optim.Adam(model.module.mrnd.parameters(), lr=1e-3)\n",
    "    \n",
    "    params = {'model' : model.module.mrnd, \n",
    "        'criterion': loss_fn,  \n",
    "        'optimizer': optimizer, \n",
    "        'callbacks': [savebest,  ptt.PrintCallback()] #ptt.PlotCallback(),\n",
    "    }\n",
    "\n",
    "else:    \n",
    "    optimizer =  optim.Adam(model.mrnd.parameters(), lr=1e-3)\n",
    "    params = {'model' : model.mrnd, \n",
    "        'criterion': loss_fn,  \n",
    "        'optimizer': optimizer, \n",
    "        'callbacks': [savebest,  ptt.PrintCallback()] #ptt.PlotCallback(),\n",
    "    }\n",
    "       \n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ptt.DeepNetTrainer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 50 epochs\n",
      "  1:   0.7s   T: 2.49544   V: 2.31245 best\n",
      "  2:   0.5s   T: 2.13542   V: 2.03268 best\n",
      "  3:   0.5s   T: 1.61395   V: 1.38686 best\n",
      "  4:   0.5s   T: 1.02466   V: 0.85323 best\n",
      "  5:   0.5s   T: 0.73293   V: 0.53910 best\n",
      "  6:   0.5s   T: 0.46047   V: 0.45021 best\n",
      "  7:   0.5s   T: 0.29975   V: 0.34022 best\n",
      "  8:   0.5s   T: 0.35059   V: 1.04217 \n",
      "  9:   0.5s   T: 0.40410   V: 0.28891 best\n",
      " 10:   0.5s   T: 0.27423   V: 0.20944 best\n",
      " 11:   0.6s   T: 0.16131   V: 0.18468 best\n",
      " 12:   0.5s   T: 0.12890   V: 0.20248 \n",
      " 13:   0.5s   T: 0.18973   V: 0.24373 \n",
      " 14:   0.6s   T: 0.11647   V: 0.21054 \n",
      " 15:   0.6s   T: 0.12388   V: 0.24007 \n",
      " 16:   0.6s   T: 0.11262   V: 0.15856 best\n",
      " 17:   0.6s   T: 0.07499   V: 0.12346 best\n",
      " 18:   0.6s   T: 0.06110   V: 0.13708 \n",
      " 19:   0.6s   T: 0.05318   V: 0.11642 best\n",
      " 20:   0.6s   T: 0.04859   V: 0.10704 best\n",
      " 21:   0.5s   T: 0.04557   V: 0.13835 \n",
      " 22:   0.5s   T: 0.05053   V: 0.14537 \n",
      " 23:   0.5s   T: 0.04899   V: 0.22458 \n",
      " 24:   0.5s   T: 1.27157   V: 0.35446 \n",
      " 25:   0.5s   T: 0.16009   V: 0.17287 \n",
      " 26:   0.5s   T: 0.09902   V: 0.11744 \n",
      " 27:   0.5s   T: 0.08191   V: 0.10607 best\n",
      " 28:   0.5s   T: 0.06301   V: 0.13020 \n",
      " 29:   0.5s   T: 0.05715   V: 0.16687 \n",
      " 30:   0.5s   T: 0.05519   V: 0.14744 \n",
      " 31:   0.5s   T: 0.04678   V: 0.11372 \n",
      " 32:   0.5s   T: 0.04629   V: 0.19565 \n",
      " 33:   0.5s   T: 0.05053   V: 0.14122 \n",
      " 34:   0.5s   T: 0.06147   V: 0.10191 best\n",
      " 35:   0.5s   T: 0.03448   V: 0.22405 \n",
      " 36:   0.5s   T: 0.03427   V: 0.15126 \n",
      " 37:   0.5s   T: 0.46539   V: 0.35370 \n",
      " 38:   0.5s   T: 0.10937   V: 0.13015 \n",
      " 39:   0.6s   T: 0.04264   V: 0.08778 best\n",
      " 40:   0.6s   T: 0.03663   V: 0.07106 best\n",
      " 41:   0.5s   T: 0.02534   V: 0.05800 best\n",
      " 42:   0.5s   T: 0.02211   V: 0.06009 \n",
      " 43:   0.5s   T: 0.02027   V: 0.06312 \n",
      " 44:   0.5s   T: 0.01880   V: 0.06194 \n",
      " 45:   0.6s   T: 0.01813   V: 0.05591 best\n",
      " 46:   0.5s   T: 0.01325   V: 0.07113 \n",
      " 47:   0.5s   T: 0.01266   V: 0.06865 \n",
      " 48:   0.5s   T: 0.01146   V: 0.05951 \n",
      " 49:   0.5s   T: 0.01046   V: 0.05438 best\n",
      " 50:   0.6s   T: 0.01302   V: 0.05249 best\n",
      "Best model was saved at epoch 50 with loss 0.05249: /mnt/home/e209440/models/ResNetDistractDriver\n",
      "Stop training at epoch: 50/50\n"
     ]
    }
   ],
   "source": [
    "trainer.fit_loader(num_epochs, dset_loaders_convnet['train'], dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mrnd = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    !free -h\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2save = './figures/results_metrics.png'\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "metrics_map = {'losses': 'Loss', 'acc': 'Acuracy'}\n",
    "\n",
    "metrics_eval_nb = len(trainer.metrics['train'].keys())\n",
    "count = 1\n",
    "for metric in trainer.metrics['train'].keys():\n",
    "    plt.subplot(1,metrics_eval_nb, count)\n",
    "    plt.plot(trainer.metrics['train'][metric], 'o-b', label = 'train')\n",
    "    plt.plot(trainer.metrics['valid'][metric], 'o-r', label = 'valid')\n",
    "    count += 1\n",
    "    plt.xlabel('Epochs', fontsize = 12)\n",
    "    plt.ylabel(metrics_map[metric], fontsize = 12)\n",
    "    plt.title(metrics_map[metric] + \" during the model's training\", fontsize = 16)\n",
    "    plt.legend()\n",
    "fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = trainer.evaluate_loader(dset_loaders_convnet['train'])\n",
    "valid_eval = trainer.evaluate_loader(dset_loaders_convnet['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval, valid_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders_wshuffle = _create_dataLoader(dsets, batch_size, cpu_count, pin_memory=use_gpu, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = predict(dset_loaders_wshuffle['train'], model)\n",
    "result_valid = predict(dset_loaders_wshuffle['valid'], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(result_valid):\n",
    "    _, predicted = torch.max(result_valid, 1)\n",
    "    return predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2numpy(result):\n",
    "    return result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train['pred'] = getPrediction(result_train['pred'])\n",
    "result_valid['pred'] = getPrediction(result_valid['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train['pred'] = tensor2numpy(result_train['pred'])\n",
    "result_train['true'] = tensor2numpy(result_train['true'])\n",
    "\n",
    "result_valid['pred'] = tensor2numpy(result_valid['pred'])\n",
    "result_valid['true'] = tensor2numpy(result_valid['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = (result_train['true'] == result_train['pred']).sum()\n",
    "correct_valid = (result_valid['true'] == result_valid['pred']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: ', correct_train, '/', len(conv_dset['train']) )\n",
    "print('Valid: ', correct_valid, '/', len(conv_dset['valid']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_correct = np.where(result_train['true'] == result_train['pred'])[0]\n",
    "lst_incorrect = np.where(result_train['true'] != result_train['pred'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(dsets, lst, path2save = []):\n",
    "    maxSubPlot = 4\n",
    "    if len(lst)<4:\n",
    "        maxSubPlot = len(lst)\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    for i, j in enumerate(range(0,maxSubPlot)):\n",
    "        fig.add_subplot(1, maxSubPlot, i+1)\n",
    "        (inputs, output) = dsets[lst[j]]\n",
    "        img = denormalize(inputs.numpy())\n",
    "        img = np.clip(img, 0, 1.0)\n",
    "        plt.imshow(img)\n",
    "        #plt.title('{0} / {1}'.format(labels['c'+str(output)],  labels[('c'+str(result_train['pred'][lst[j]]))]))    \n",
    "        plt.title('{0} / {1}'.format(('c'+str(output)),  ('c'+str(result_train['pred'][lst[j]]))))    \n",
    "        plt.axis('off')\n",
    "    if len(path2save) !=0:\n",
    "        fig.savefig(path2save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(dsets['train'], lst_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(dsets['train'], lst_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(results):\n",
    "    mc = np.array(pd.crosstab(results['pred'], results['true']))\n",
    "    plt.imshow(mc/mc.sum(axis=1))\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plot_confusion(result_train)\n",
    "plt.title('Train dataset')\n",
    "plt.subplot(1,2,2)\n",
    "plot_confusion(result_valid)\n",
    "plt.title('Valid dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layers_weight(img_width, img_height, conv_model = model.mrnc, ncols = 8, H = 14, W=30):\n",
    "\n",
    "\n",
    "    rand_idx = random.randrange(0, len(dsets['train']))\n",
    "    input, _ = dsets['train'][rand_idx]\n",
    "    input = input.view(1, 3, img_width, img_height)\n",
    "\n",
    "    if use_gpu:\n",
    "        x = Variable(input.cuda())\n",
    "    else:\n",
    "        x = Variable(input)\n",
    "\n",
    "\n",
    "    for name, layer in conv_model.named_children():\n",
    "        x = layer(x)\n",
    "        grid = torchvision.utils.make_grid(torch.transpose(x.data, 0, 1), normalize=True, \n",
    "                                           pad_value=1.0, padding=1).cpu().numpy()\n",
    "\n",
    "        if name == 'max_pool':\n",
    "            H /= 3/2\n",
    "            W /= 3/2\n",
    "        fig = plt.figure(figsize=(H,W))\n",
    "        plt.imshow(grid.transpose((1,2,0)))\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layers_weight(img_width=224, img_height=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
