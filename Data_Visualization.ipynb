{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "from src.imgnet_utils import denormalize\n",
    "\n",
    "from src.data_loader import _create_dataLoader\n",
    "\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "\n",
    "from src.plot_utils import (plot_classes, plot_distribution,\n",
    "                            statistical_analysis_image, classDistribution,\n",
    "                            plot_metrics,visualize_predictions,\n",
    "                            plot_cm_train_valid,plot_layers_weight)\n",
    "\n",
    "from src.extractor_utils import (predict, getPrediction,features_saving,\n",
    "                                 features_loading, torch_summarize)\n",
    "\n",
    "from src.convnet_models import (MyResNet, MyInception, MyDenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} GPU's available:\".format(torch.cuda.device_count()) )\n",
    "cpu_count = torch.multiprocessing.cpu_count()\n",
    "print(\"\\ncpu_count: {}\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "use_DataParalel= True \n",
    "use_CPU= False         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "\n",
    "if use_gpu:\n",
    "    if use_DataParalel:\n",
    "        print(\"Using DataParalel in all {} GPUS\".format(torch.cuda.device_count()))\n",
    "    else:\n",
    "        print('Using only one GPU') #{} '.format(device_id))\n",
    "else:\n",
    "    print(\"Using {} CPU's\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Choose dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = \"/mnt/home/e209440/data/train\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img_width = img_height=300 #to use InceptionV3 it must img_width and img_height be changed to 300\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ])\n",
    "}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating  Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "use_only = 1.0 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'train': KaggleSafeDriverDataset(path2train, transforms=data_transforms['train'], use_only=use_only),\n",
    "    'valid': KaggleSafeDriverDataset(path2train, transforms=data_transforms['train'],  is_val=True, use_only=use_only)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = _create_dataLoader(dsets, batch_size, pin_memory=False, use_shuffle= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples distribution for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDistribution(dsets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_analysis_image(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_resnet = True\n",
    "use_inception = False\n",
    "use_denseNet = False\n",
    "\n",
    "if use_resnet:\n",
    "    print('Using ResNet model')\n",
    "    model_name = \"ResNet\"\n",
    "    model = MyResNet()\n",
    "elif use_inception:\n",
    "    print('Using Inception model')\n",
    "    model_name = \"Inception\"\n",
    "    model = MyInception()\n",
    "elif use_denseNet:\n",
    "    print('Using DenseNet model')\n",
    "    model_name = \"DenseNet\"    \n",
    "    model = MyDenseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot layers models Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layers_weight(dsets,img_width=img_width, img_height=img_height,conv_model = model.mrnc,use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mismatch predictions (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2results = \"/mnt/home/r120084/project/state-farm-distracted-driver-detection/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loaded features with shapes: \\n\")\n",
    "npzfile = np.load(path2results+\"/\" + \"results_valid_\"+ model_name+ \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_matrix = torch.nn.functional.softmax(torch.from_numpy(npzfile['pred']))\n",
    "probas, _ = torch.max(probas_matrix, 1)\n",
    "probas = probas.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_valid = {'probas': probas, 'pred': np.argmax(npzfile['pred'], 1), 'true': npzfile['true']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_egal = np.where(result_valid['true'] == result_valid['pred'])[0]\n",
    "i_not_egal = np.where(result_valid['true'] != result_valid['pred'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right predictions with higher probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_predictions = np.argsort(result_valid['probas'][i_egal])[::-1]\n",
    "y_top = i_egal[top_predictions]\n",
    "\n",
    "visualize_predictions(dsets['valid'], y_top,  result_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Right forecasts with lower probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_predictions = np.argsort(result_valid['probas'][i_egal])\n",
    "y_bot = i_egal[top_predictions]\n",
    "\n",
    "visualize_predictions(dsets['valid'],  y_bot, result_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong forecasts with higher probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_predictions = np.argsort(result_valid['probas'][i_not_egal])[::-1]\n",
    "y_top_not = i_not_egal[top_predictions]\n",
    "\n",
    "visualize_predictions(dsets['valid'],  y_top_not, result_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong forecasts with lower probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_predictions = np.argsort(result_valid['probas'][i_not_egal])\n",
    "y_bot_not = i_not_egal[top_predictions]\n",
    "\n",
    "visualize_predictions(dsets['valid'],  y_bot_not, result_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell it will be used to show what kind of transformations we have tried to do, do not move to a .py file because we will work on it yet.\n",
    "\n",
    "composed = transforms.Compose([transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std)])\n",
    "\n",
    "composed1 = transforms.Compose([\n",
    "                                transforms.CenterCrop((220,320)),\n",
    "                                transforms.Scale((img_width, img_height)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(imagenet_mean, imagenet_std)])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure(figsize = (20,5))\n",
    "for i, tsfrm in enumerate([composed, composed1]):\n",
    "    dset_aux = KaggleSafeDriverDataset(path2train, transforms=tsfrm, use_only=use_only)\n",
    "    (inputs, cls) = dset_aux[60]\n",
    "    print(inputs.numpy().shape)\n",
    "    img = denormalize(inputs.numpy())\n",
    "    img = np.clip(img, 0, 1.0)\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2metrics = '/mnt/home/r120084/project/state-farm-distracted-driver-detection/metrics/metrics_'+ model_name+'.csv'\n",
    "metrics = pd.read_csv(path2metrics).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming dictionary keys\n",
    "metrics['train']['acc'] = metrics['train'].pop(0)\n",
    "metrics['train']['losses'] = metrics['train'].pop(1)\n",
    "\n",
    "metrics['valid']['acc'] = metrics['valid'].pop(0)\n",
    "metrics['valid']['losses'] = metrics['valid'].pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics, './figures/results_metrics_'+model_name+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
