{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import  Dataset, TensorDataset, DataLoader\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "from src.imgnet_utils import denormalize\n",
    "\n",
    "from src.data_loader import _create_dataLoader\n",
    "\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "\n",
    "from src.plot_utils import (plot_classes, plot_distribution,\n",
    "                            statistical_analysis_image, classDistribution,\n",
    "                            plot_metrics,visualize_predictions,\n",
    "                            plot_cm_train_valid,plot_layers_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GPU's available:\n",
      "\n",
      "cpu_count: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"{} GPU's available:\".format(torch.cuda.device_count()) )\n",
    "cpu_count = torch.multiprocessing.cpu_count()\n",
    "print(\"\\ncpu_count: {}\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 24 CPU's\n"
     ]
    }
   ],
   "source": [
    "use_gpu = False\n",
    "use_DataParalel= True \n",
    "use_CPU= False         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "\n",
    "if use_gpu:\n",
    "    if use_DataParalel:\n",
    "        print(\"Using DataParalel in all {} GPUS\".format(torch.cuda.device_count()))\n",
    "    else:\n",
    "        print('Using only one GPU') #{} '.format(device_id))\n",
    "else:\n",
    "    print(\"Using {} CPU's\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Choose dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = \"/mnt/home/e209440/data/train\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img_width = img_height=300 #to use InceptionV3 it must img_width and img_height be changed to 300\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ])\n",
    "}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating  Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "use_only = 1.0 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'train': KaggleSafeDriverDataset(path2train, transforms=data_transforms['train'],use_only=use_only)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = _create_dataLoader(dsets, batch_size, pin_memory=False, use_shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2results = \"/mnt/home/r120084/project/state-farm-distracted-driver-detection/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features with shapes: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded features with shapes: \\n\")\n",
    "npzfile = np.load(path2results+\"/\" + \"results_valid_Resnet18_2017-11-26-14-41.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.1797967 ,  -8.97665405, -25.40347862, ...,  -2.87480593,\n",
       "          6.42260313,  22.02296066],\n",
       "       [ -8.17194271,  -0.84254789,  -5.31919765, ...,  -4.72954273,\n",
       "         -2.83368874,  -2.24675798],\n",
       "       [ -2.64065576,   3.79761171,  16.34770203, ...,  -4.54322481,\n",
       "         -6.01621675, -18.60191727],\n",
       "       ..., \n",
       "       [ -0.41439867, -31.58727837, -15.49133015, ...,  -5.05358171,\n",
       "        -10.47488117,  -9.14722633],\n",
       "       [  0.76069754,   3.82887578,  15.27601433, ...,  -4.48759747,\n",
       "         -1.33089745, -11.6917448 ],\n",
       "       [ -2.36654735, -23.29958916, -10.22987747, ...,  -9.92538166,\n",
       "         -6.81051111, -10.76055813]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.from_numpy(npzfile['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 7.1798e+00 -8.9767e+00 -2.5403e+01  ...  -2.8748e+00  6.4226e+00  2.2023e+01\n",
       "-8.1719e+00 -8.4255e-01 -5.3192e+00  ...  -4.7295e+00 -2.8337e+00 -2.2468e+00\n",
       "-2.6407e+00  3.7976e+00  1.6348e+01  ...  -4.5432e+00 -6.0162e+00 -1.8602e+01\n",
       "                ...                   â‹±                   ...                \n",
       "-4.1440e-01 -3.1587e+01 -1.5491e+01  ...  -5.0536e+00 -1.0475e+01 -9.1472e+00\n",
       " 7.6070e-01  3.8289e+00  1.5276e+01  ...  -4.4876e+00 -1.3309e+00 -1.1692e+01\n",
       "-2.3665e+00 -2.3300e+01 -1.0230e+01  ...  -9.9254e+00 -6.8105e+00 -1.0761e+01\n",
       "[torch.FloatTensor of size 4484x10]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = getPrediction(result_train)\n",
    "result_valid = getPrediction(result_valid)\n",
    "# result_test['pred'] must be an array of probabilities to make the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = (result_train['true'] == result_train['pred']).sum()\n",
    "correct_valid = (result_valid['true'] == result_valid['pred']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(dsets['valid'], result_valid, correct_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move this to Data Visualization\n",
    "#plot_layers_weight(dsets,img_width=img_width, img_height=img_height,conv_model = model.mrnc,use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell it will be used to show what kind of transformations we have tried to do, do not move to a .py file because we will work on it yet.\n",
    "\n",
    "composed = transforms.Compose([transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std)])\n",
    "\n",
    "composed1 = transforms.Compose([\n",
    "                                transforms.CenterCrop((220,320)),\n",
    "                                transforms.Scale((img_width, img_height)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(imagenet_mean, imagenet_std)])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure(figsize = (20,5))\n",
    "for i, tsfrm in enumerate([composed, composed1]):\n",
    "    dset_aux = KaggleSafeDriverDataset(path2train, transforms=tsfrm, use_only=use_only)\n",
    "    (inputs, cls) = dset_aux[60]\n",
    "    print(inputs.numpy().shape)\n",
    "    img = denormalize(inputs.numpy())\n",
    "    img = np.clip(img, 0, 1.0)\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classes(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_analysis_image(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classDistribution(dsets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the metrics of the train model (could be a csv file or something else) an plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and plot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2metrics = '/mnt/home/r120084/project/state-farm-distracted-driver-detection/metrics/metrics_Resnet18_2017-11-25-12-38.csv'\n",
    "metrics = pd.read_csv(path2metrics).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming dictionary keys\n",
    "metrics['train']['acc'] = metrics['train'].pop(0)\n",
    "metrics['train']['losses'] = metrics['train'].pop(1)\n",
    "\n",
    "metrics['valid']['acc'] = metrics['valid'].pop(0)\n",
    "metrics['valid']['losses'] = metrics['valid'].pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2results = '/mnt/home/r120084/project/state-farm-distracted-driver-detection/results/results_Resnet18_2017-11-25-15-49.csv'\n",
    "results = pd.read_csv(path2results).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#renaming dictionary keys\n",
    "results['train']['pred'] = results['train'].pop(0)\n",
    "results['train']['true'] = results['train'].pop(1) \n",
    "\n",
    "results['valid']['pred'] = results['valid'].pop(0)\n",
    "results['valid']['true'] = results['valid'].pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_predictions(dsets['valid'], result_valid, correct_pred = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(dsets['valid'], result_valid, correct_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_resnet = True\n",
    "use_inception = False\n",
    "use_denseNet = False\n",
    "\n",
    "if use_resnet:\n",
    "    print('Using ResNet model')\n",
    "    model_name = \"ResNet\"\n",
    "    model = MyResNet()\n",
    "if use_inception:\n",
    "    print('Using Inception model')\n",
    "    model_name = \"Inception\"\n",
    "    model = MyInception()\n",
    "if use_denseNet:\n",
    "    print('Using DenseNet model')\n",
    "    model_name = \"DenseNet\"    \n",
    "    model = MyDenseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    if use_DataParalel:\n",
    "        print(\"Using all GPU's \")\n",
    "        model.mrnc = torch.nn.DataParallel(model.mrnc) #device_ids=[1,3]\n",
    "        model.mrnc = model.mrnc.cuda()\n",
    "        model.mrnd = torch.nn.DataParallel(model.mrnd) #device_ids=[1,3]\n",
    "        model.mrnd = model.mrnd.cuda()\n",
    "    else:\n",
    "        print('Using GPU')# {}'.format(device_id))\n",
    "        model.cuda()\n",
    "else:\n",
    "    print(\"Using CPU's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move this to Data Visualization\n",
    "#plot_layers_weight(dsets,img_width=img_width, img_height=img_height,conv_model = model.mrnc,use_gpu=use_gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
